{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset chosen for this project is a Wikipedia API used to extract data for events of 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Of Contents\n",
    "\n",
    "1. [Data Wrangling](#processdata)\n",
    "2. [Custom Query Completion](#querycompl)\n",
    "3. [Custom Performance Demonstration](#demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "<a id =\"processdata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import requests\n",
    "from dateutil.parser import parse\n",
    "from openai.embeddings_utils import distances_from_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter OpenAI API key (input hidden): ········\n",
      "API key configured (last 4 chars): ****1104\n"
     ]
    }
   ],
   "source": [
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "def get_openai_api_key():\n",
    "    key = getpass.getpass(\"Enter OpenAI API key (input hidden): \").strip()\n",
    "    while not key:\n",
    "        print(\"API key cannot be empty!\")\n",
    "        key = getpass.getpass(\"Enter OpenAI API key (input hidden): \").strip()\n",
    "\n",
    "    print(f\"API key configured (last 4 chars): ****{key[-4:]}\")\n",
    "    return key\n",
    "\n",
    "openai.api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Dataset & Embedding Functions\n",
    "# ===============================\n",
    "\n",
    "def load_dataset():\n",
    "    # Get the Wikipedia page for \"2024\" since OpenAI's models stop in 2021\n",
    "    resp = requests.get(\"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&exlimit=1&titles=2024&explaintext=1&formatversion=2&format=json\")\n",
    "\n",
    "    # Load page text into a dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df[\"text\"] = resp.json()[\"query\"][\"pages\"][0][\"extract\"].split(\"\\n\")\n",
    "    \n",
    "    # Clean up text to remove empty lines and headings\n",
    "    df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "    \n",
    "    # In some cases dates are used as headings instead of being part of the\n",
    "    # text sample; adjust so dated text samples start with dates\n",
    "    prefix = \"\"\n",
    "    for (i, row) in df.iterrows():\n",
    "        # If the row already has \" - \", it already has the needed date prefix\n",
    "        if \" – \" not in row[\"text\"]:\n",
    "            try:\n",
    "                 # If the row's text is a date, set it as the new prefix\n",
    "                 parse(row[\"text\"])\n",
    "                 prefix = row[\"text\"]\n",
    "            except:\n",
    "                 # If the row's text isn't a date, add the prefix\n",
    "                 row[\"text\"] = prefix + \" – \" + row[\"text\"]\n",
    "    df = df[df[\"text\"].str.contains(\" – \")]\n",
    " \n",
    "    return df\n",
    "\n",
    "def get_embedding_for_text(text, embedding_model_name=\"text-embedding-ada-002\"):\n",
    "    #Get embeddings from the model\n",
    "    response = openai.Embedding.create(input=[text], model=embedding_model_name)\n",
    "    if 'data' in response and isinstance(response['data'], list):\n",
    "        return response['data'][0]['embedding']\n",
    "    else:\n",
    "        print(\"Error: unexpected response for text:\", text)\n",
    "        return None\n",
    "\n",
    "def generate_embeddings(df, embedding_model_name=\"text-embedding-ada-002\"):\n",
    "    embeddings = []\n",
    "    for i, row in df.iterrows():\n",
    "        print(f\"Processing index {i}\")\n",
    "        try:\n",
    "            text = row['text']\n",
    "            embedding = get_embedding_for_text(text, embedding_model_name)\n",
    "            embeddings.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception at index {i}: {e}\")\n",
    "            embeddings.append(None)\n",
    "    df[\"embeddings\"] = embeddings\n",
    "    return df\n",
    "\n",
    "def save_embeddings(df, output_file):\n",
    "    df.to_csv(output_file) \n",
    "\n",
    "def load_embeddings(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"embeddings\"] = df[\"embeddings\"].apply(eval).apply(np.array) \n",
    "    return df\n",
    "\n",
    "def get_relevant_rows(question, df, embedding_model_name=\"text-embedding-ada-002\", top_n=10):\n",
    "    question_embedding = openai.Embedding.create(\n",
    "        model=embedding_model_name,\n",
    "        input=question\n",
    "    )\n",
    "    # Check if the response contains the 'data' key\n",
    "    if 'data' in question_embedding and len(question_embedding['data']) > 0:\n",
    "        question_embedding = question_embedding['data'][0]['embedding']\n",
    "    else:\n",
    "        print(f\"Warning: 'data' key not found or empty in question embedding response. Response: {question_embedding}\")\n",
    "        return df.head(top_n)  # Return top rows as fallback\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    df_copy['distance'] = distances_from_embeddings(question_embedding, df_copy['embeddings'].values, distance_metric=\"cosine\")  \n",
    "\n",
    "    return df_copy.nsmallest(top_n, 'distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "<a id =\"querycompl\"></a>\n",
    "In the cells below, we compose a custom query using our chosen dataset and retrieve results from an OpenAI `Completion` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Prompt Creation & Answering\n",
    "# ===============================\n",
    "\n",
    "def create_prompt(question, df, max_token_count=1500):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the question based on the context below. If the question can't be answered based on the context, say \"I don't know.\"\n",
    "\n",
    "    Context: {}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Question: {}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + len(tokenizer.encode(question))  \n",
    "\n",
    "    context = []\n",
    "    for text in df[\"text\"].values:\n",
    "        tokens_in_text = len(tokenizer.encode(text))\n",
    "        if current_token_count + tokens_in_text <= max_token_count:\n",
    "            context.append(text)\n",
    "            current_token_count += tokens_in_text\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "\n",
    "def get_openai_answer(prompt, max_answer_tokens=150):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        # Check if the response contains the 'choices' key and it's not empty.\n",
    "        if 'choices' in response and len(response['choices']) > 0:\n",
    "            return response[\"choices\"][0][\"text\"].strip()  \n",
    "        else:\n",
    "            print(f\"Warning: 'choices' key not found or empty in response. Response: {response}\")\n",
    "            return \"No answer found in response.\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"An error occurred.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Question Answering Functions\n",
    "# ===============================\n",
    "\n",
    "def answer_basic_question(question, max_answer_tokens=150):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=question,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()  \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"An error occurred.\"\n",
    "\n",
    "def answer_question_with_context(question, df, max_prompt_tokens=1500, max_answer_tokens=150, top_n=10):\n",
    "    relevant_rows = get_relevant_rows(question, df, top_n=top_n)\n",
    "    prompt = create_prompt(question, relevant_rows, max_token_count=max_prompt_tokens)  \n",
    "    return get_openai_answer(prompt, max_answer_tokens=max_answer_tokens)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Main Function\n",
    "# ===============================\n",
    "\n",
    "def main():\n",
    "    df = load_dataset()  \n",
    "\n",
    "    # Generate embeddings and save them to a CSV file.\n",
    "    df = generate_embeddings(df)\n",
    "    save_embeddings(df, \"./embeddings_with_vectors.csv\")  \n",
    "\n",
    "    df = load_embeddings(\"./embeddings_with_vectors.csv\")  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Execution\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"Ask a question (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    # Placeholder for query processing and response generation\n",
    "    print(f\"You asked: {user_input}\")\n",
    "    #print(\"(Response generation logic would go here)\")\n",
    "    print(answer_question_with_context(user_input, data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
